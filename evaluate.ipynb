{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Measurement Evaluation\n",
    "\n",
    "This notebook evaluates power consumption and energy trends from experiment results.  \n",
    "The data is collected from multiple nodes and analyzed for insights into power usage, voltage, and energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Result Folder\n",
    "\n",
    "Before loading data, enter the path to your experiment result folder.  \n",
    "By default, the last used path is shown, but you can change it to any valid directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Base path where result folders are stored\n",
    "base_result_folder = \"/srv/testbed/results/warmuth/default/\"\n",
    "\n",
    "# Default result folder (full path)\n",
    "default_result_folder = os.path.join(base_result_folder, \"2025-03-03_17-19-02_135410\")\n",
    "\n",
    "# Ask user for input with a default value\n",
    "user_input = input(f\"Enter result folder path [{default_result_folder}]: \").strip()\n",
    "\n",
    "# If input is empty, use default\n",
    "if not user_input:\n",
    "    RESULT_FOLDER = default_result_folder\n",
    "# If input contains '/', assume it's a full path\n",
    "elif \"/\" in user_input:\n",
    "    RESULT_FOLDER = user_input\n",
    "# If input looks like only a timestamp, prepend the base path\n",
    "else:\n",
    "    RESULT_FOLDER = os.path.join(base_result_folder, user_input)\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(RESULT_FOLDER):\n",
    "    raise FileNotFoundError(f\"Result folder not found: {RESULT_FOLDER}\")\n",
    "\n",
    "display(f\"Using result folder: {RESULT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creator Information\n",
    "\n",
    "The following table presents details about the experiment's creator, extracted from the **RO-Crate metadata**.\n",
    "\n",
    "- **Name:** The name of the creator.\n",
    "- **ORCID:** A unique researcher identifier, linked to the official ORCID profile.\n",
    "- **Affiliation:** The institution the creator is affiliated with.\n",
    "- **Affiliation ROR:** A **Research Organization Registry (ROR) ID**, used for standard identification of research institutions.\n",
    "- **Affiliation URL:** A direct link to the institution’s website.\n",
    "\n",
    "## TODO\n",
    "- Bezug Creator/Author besser darstellen -> ähnlich wie in Publication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def load_creator_info():\n",
    "    \"\"\"\n",
    "    Extract creator information from the RO-Crate metadata JSON file.\n",
    "    Retrieves the creator's name, ORCID, and affiliation details.\n",
    "    \"\"\"\n",
    "    rocrate_path = os.path.join(RESULT_FOLDER, \"ro-crate-metadata.json\")\n",
    "    if not os.path.exists(rocrate_path):\n",
    "        raise FileNotFoundError(f\"RO-Crate metadata file not found: {rocrate_path}\")\n",
    "\n",
    "    with open(rocrate_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    creator_info = {\n",
    "        \"Name\": \"Unknown\",\n",
    "        \"ORCID\": \"Unknown\",\n",
    "        \"Affiliation Name\": \"Unknown\",\n",
    "        \"Affiliation ROR\": \"Unknown\",\n",
    "        \"Affiliation URL\": \"Unknown\"\n",
    "    }\n",
    "\n",
    "    # Find the creator entry\n",
    "    for item in metadata.get(\"@graph\", []):\n",
    "        if \"keywords\" in item and \"creator\" in item[\"keywords\"]:\n",
    "            creator_info[\"Name\"] = item.get(\"name\", \"Unknown\")\n",
    "            creator_info[\"ORCID\"] = item.get(\"@id\", \"Unknown\")\n",
    "\n",
    "            # Look up affiliation\n",
    "            affiliation_id = item.get(\"affiliation\", {}).get(\"@id\", None)\n",
    "            if affiliation_id:\n",
    "                for org in metadata.get(\"@graph\", []):\n",
    "                    if org.get(\"@id\") == affiliation_id:\n",
    "                        creator_info[\"Affiliation Name\"] = org.get(\"name\", \"Unknown\")\n",
    "                        creator_info[\"Affiliation ROR\"] = org.get(\"@id\", \"Unknown\")\n",
    "                        creator_info[\"Affiliation URL\"] = org.get(\"url\", \"Unknown\")\n",
    "\n",
    "    return creator_info\n",
    "\n",
    "creator_data = load_creator_info()\n",
    "creator_df = pd.DataFrame([creator_data])\n",
    "\n",
    "# Convert ORCID and Affiliation links to clickable format\n",
    "def make_link(text, url):\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{text}</a>' if url != \"Unknown\" else \"Unknown\"\n",
    "\n",
    "creator_df[\"ORCID\"] = creator_df[\"ORCID\"].apply(lambda x: make_link(\"ORCID Profile\", x))\n",
    "creator_df[\"Affiliation ROR\"] = creator_df[\"Affiliation ROR\"].apply(lambda x: make_link(\"ROR ID\", x))\n",
    "creator_df[\"Affiliation URL\"] = creator_df[\"Affiliation URL\"].apply(lambda x: make_link(\"University Website\", x))\n",
    "\n",
    "creator_df.rename(columns={\n",
    "    \"Name\": \"Creator Name\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Apply table styling\n",
    "html_table = creator_df.to_html(escape=False, index=False)\n",
    "styled_table = f\"\"\"\n",
    "<style>\n",
    "    table {{ width: 70%; border-collapse: collapse; margin: 20px 0; }}\n",
    "    th, td {{ padding: 8px 12px; border: 1px solid #ddd; text-align: left; }}\n",
    "    th {{ background-color: #f4f4f4; font-weight: bold; }}\n",
    "</style>\n",
    "{html_table}\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(styled_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Information & Topology Visualization\n",
    "\n",
    "Each experiment setup includes metadata about the participating nodes.  \n",
    "This section extracts details such as:\n",
    "- Node names\n",
    "- Fully Qualified Domain Names (FQDN)\n",
    "- Topology information (if available).\n",
    "\n",
    "If a **topology visualization** is provided in the RO-Crate metadata, it is displayed below.\n",
    "\n",
    "## TODO\n",
    "- Testbed klar machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "def load_rocrate_metadata():\n",
    "    \"\"\"\n",
    "    Load and parse the RO-Crate metadata JSON file.\n",
    "    Extract node information and locate paths for hardware details and topology PDFs.\n",
    "    \"\"\"\n",
    "    rocrate_path = os.path.join(RESULT_FOLDER, \"ro-crate-metadata.json\")\n",
    "    if not os.path.exists(rocrate_path):\n",
    "        raise FileNotFoundError(f\"RO-Crate metadata file not found: {rocrate_path}\")\n",
    "\n",
    "    with open(rocrate_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    nodes_info = []\n",
    "\n",
    "    for item in metadata.get(\"@graph\", []):\n",
    "        if \"keywords\" in item and \"node\" in item[\"keywords\"]:\n",
    "            node_name = item.get(\"name\", \"Unknown\")\n",
    "            fqdn = item.get(\"fqdn\", \"Unknown\")\n",
    "\n",
    "            # Check for visualized topology PDF\n",
    "            topology_pdf_path = None\n",
    "            if isinstance(item.get(\"visualizedTopology\", {}), dict) and \"@id\" in item[\"visualizedTopology\"]:\n",
    "                topology_pdf_path = os.path.join(RESULT_FOLDER, item[\"visualizedTopology\"][\"@id\"])\n",
    "                if not os.path.exists(topology_pdf_path):\n",
    "                    topology_pdf_path = None  # Ignore missing PDFs\n",
    "\n",
    "            # Check for hardware information JSON\n",
    "            hardware_json_path = None\n",
    "            if isinstance(item.get(\"hardware\", {}), dict) and \"@id\" in item[\"hardware\"]:\n",
    "                hardware_json_path = os.path.join(RESULT_FOLDER, item[\"hardware\"][\"@id\"])\n",
    "                if not os.path.exists(hardware_json_path):\n",
    "                    hardware_json_path = None  # Ignore missing hardware files\n",
    "\n",
    "            nodes_info.append({\n",
    "                \"name\": node_name if isinstance(node_name, str) else \"Unknown\",\n",
    "                \"fqdn\": fqdn if isinstance(fqdn, str) else \"Unknown\",\n",
    "                \"topology_pdf\": topology_pdf_path if topology_pdf_path else \"None\",\n",
    "                \"hardware_json\": hardware_json_path if hardware_json_path else \"None\"\n",
    "            })\n",
    "\n",
    "    return nodes_info\n",
    "\n",
    "def extract_hardware_info(hardware_json_path):\n",
    "    \"\"\"\n",
    "    Extract processor, network, and memory information from the hardware.json file.\n",
    "    Returns a dictionary with processor details, NIC models, and installed memory.\n",
    "    \"\"\"\n",
    "    if not hardware_json_path or not os.path.exists(hardware_json_path):\n",
    "        return {\n",
    "            \"cpu_model\": \"Unknown\", \"cpu_cores\": \"Unknown\", \"cpu_threads\": \"Unknown\",\n",
    "            \"memory\": \"Unknown\", \"nic_models\": \"Unknown\"\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        with open(hardware_json_path, \"r\") as f:\n",
    "            hardware_data = json.load(f)\n",
    "\n",
    "        # Extract processor information\n",
    "        cpu_data = hardware_data.get(\"processor\", [{}])[0]\n",
    "        cpu_model = cpu_data.get(\"model\", \"Unknown\")\n",
    "        cpu_cores = cpu_data.get(\"cores\", \"Unknown\")\n",
    "        cpu_threads = cpu_data.get(\"threads\", \"Unknown\")\n",
    "\n",
    "        # Extract NIC models\n",
    "        nic_models = []\n",
    "        if isinstance(hardware_data.get(\"network\"), list):\n",
    "            for nic in hardware_data[\"network\"]:\n",
    "                if isinstance(nic, dict) and \"model\" in nic:\n",
    "                    nic_models.append(nic[\"model\"])\n",
    "\n",
    "        # Extract installed memory\n",
    "        memory_val = hardware_data.get(\"memory\", {}).get(\"installed_capacity_human_val\", \"Unknown\")\n",
    "        memory_unit = hardware_data.get(\"memory\", {}).get(\"installed_capacity_human_unit\", \"\")\n",
    "        memory_str = f\"{memory_val} {memory_unit}\" if isinstance(memory_val, (int, float, str)) else \"Unknown\"\n",
    "\n",
    "        return {\n",
    "            \"cpu_model\": cpu_model if isinstance(cpu_model, str) else \"Unknown\",\n",
    "            \"cpu_cores\": cpu_cores if isinstance(cpu_cores, int) else \"Unknown\",\n",
    "            \"cpu_threads\": cpu_threads if isinstance(cpu_threads, int) else \"Unknown\",\n",
    "            \"memory\": f\"RAM: {memory_str}\" if memory_str != \"Unknown\" else \"Unknown\",\n",
    "            \"nic_models\": \"<br>\".join(nic_models) if nic_models else \"No NICs detected\",\n",
    "        }\n",
    "\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return {\n",
    "            \"cpu_model\": \"Unknown\", \"cpu_cores\": \"Unknown\", \"cpu_threads\": \"Unknown\",\n",
    "            \"memory\": \"Unknown\", \"nic_models\": \"Unknown\"\n",
    "        }\n",
    "\n",
    "# Extract node metadata\n",
    "nodes_info = load_rocrate_metadata()\n",
    "\n",
    "# Convert to DataFrame\n",
    "nodes_df = pd.DataFrame(nodes_info)\n",
    "\n",
    "# Extract hardware details and merge into the DataFrame\n",
    "hardware_details = [extract_hardware_info(node[\"hardware_json\"]) for node in nodes_info]\n",
    "hardware_df = pd.DataFrame(hardware_details)\n",
    "\n",
    "# Merge hardware details with node info\n",
    "nodes_df = pd.concat([nodes_df, hardware_df], axis=1)\n",
    "\n",
    "# Remove \"hardware_json\" column (no longer needed)\n",
    "nodes_df.drop(columns=[\"hardware_json\"], inplace=True)\n",
    "\n",
    "# Convert topology path to clickable links\n",
    "def make_clickable(path):\n",
    "    if path != \"None\":\n",
    "        return f'<a href=\"{path}\" target=\"_blank\">Open PDF</a>'\n",
    "    return \"No topology available\"\n",
    "\n",
    "nodes_df[\"topology_pdf\"] = nodes_df[\"topology_pdf\"].apply(make_clickable)\n",
    "\n",
    "# Rename columns for better readability\n",
    "nodes_df.rename(columns={\n",
    "    \"name\": \"Name\",\n",
    "    \"fqdn\": \"FQDN\",\n",
    "    \"topology_pdf\": \"Topology\",\n",
    "    \"cpu_model\": \"CPU\",\n",
    "    \"cpu_cores\": \"Cores\",\n",
    "    \"cpu_threads\": \"Threads\",\n",
    "    \"memory\": \"Memory\",\n",
    "    \"nic_models\": \"NICs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorder columns for a more logical flow\n",
    "nodes_df = nodes_df[[\"Name\", \"FQDN\", \"Topology\", \"CPU\", \"Cores\", \"Threads\", \"Memory\", \"NICs\"]]\n",
    "\n",
    "# Apply table styling for better readability\n",
    "html_table = nodes_df.to_html(escape=False)\n",
    "styled_table = f\"\"\"\n",
    "<style>\n",
    "    table {{ width: 90%; border-collapse: collapse; margin: 20px 0; }}\n",
    "    th, td {{ padding: 8px 12px; border: 1px solid #ddd; text-align: left; }}\n",
    "    th {{ background-color: #f4f4f4; font-weight: bold; }}\n",
    "</style>\n",
    "{html_table}\n",
    "\"\"\"\n",
    "\n",
    "# Display the formatted table\n",
    "display(HTML(styled_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Previewing Data\n",
    "\n",
    "The energy measurement data is stored in CSV format, with each node having its own folder inside the `energy` directory.\n",
    "\n",
    "The dataset includes:\n",
    "- **Timestamp** (`timestamp`): Time when the measurement was recorded.\n",
    "- **Current** (`current_mA`): Measured current in milliamps (mA).\n",
    "- **Voltage** (`voltage_V`): Measured voltage in volts (V).\n",
    "- **Power Consumption** (`power_active_W`): Active power in watts (W).\n",
    "- **Energy Counter** (`energy_counter_Wh`): Cumulative energy usage in watt-hours (Wh).\n",
    "\n",
    "Below, we load the data and display a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "\n",
    "def load_energy_data():\n",
    "    \"\"\"\n",
    "    Load all CSV files from the energy folder inside the result folder.\n",
    "    Each node has its own subfolder containing multiple _runXX.csv files.\n",
    "    \"\"\"\n",
    "    energy_folder = os.path.join(RESULT_FOLDER, \"energy\")\n",
    "    if not os.path.exists(energy_folder):\n",
    "        raise FileNotFoundError(f\"Energy folder not found: {energy_folder}\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for node in os.listdir(energy_folder):\n",
    "        node_path = os.path.join(energy_folder, node)\n",
    "        if os.path.isdir(node_path):\n",
    "            for file in os.listdir(node_path):\n",
    "                if file.endswith(\".csv\") and \"_run\" in file:\n",
    "                    file_path = os.path.join(node_path, file)\n",
    "                    print(file_path)\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Convert timestamp for better readability\n",
    "                    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y%m%d%H%M%S%f\")\n",
    "\n",
    "                    # Add metadata columns\n",
    "                    df[\"node\"] = node\n",
    "                    df[\"run\"] = file.split(\"_run\")[-1].split(\".\")[0]  # Extract run number\n",
    "                    all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid CSV files found in the energy folder.\")\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "df = load_energy_data()\n",
    "\n",
    "# Display Data Preview\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "After loading the data, we analyze its structure using summary statistics.  \n",
    "This helps in identifying potential issues such as missing values, anomalies, or trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp_df = df.drop(columns=['node', 'run'])\n",
    "display(temp_df.describe(exclude=[np.datetime64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Consumption Over Time\n",
    "\n",
    "The following plot shows the power consumption trends over time for different nodes.  \n",
    "This helps us observe variations in power usage and detect potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"power_active_W\", hue=\"node\", style=\"run\", linewidth=2)\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Power Consumption (W)\")\n",
    "plt.title(\"Power Consumption Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node / Run\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Energy Consumption\n",
    "\n",
    "The energy counter represents the cumulative energy consumed over time.  \n",
    "This plot provides insights into the total energy usage per node and how it changes over the experiment duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"energy_counter_Wh\", hue=\"node\", style=\"run\", linewidth=2)\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Energy Counter (Wh)\")\n",
    "plt.title(\"Cumulative Energy Consumption\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node / Run\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current and Voltage Trends\n",
    "\n",
    "To better understand the electrical characteristics, we visualize:\n",
    "- **Current (mA) over time** to see how power draw fluctuates.\n",
    "- **Voltage (V) over time** to ensure stability across measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"current_mA\", hue=\"node\", style=\"run\", linewidth=2, ax=axes[0])\n",
    "axes[0].set_ylabel(\"Current (mA)\")\n",
    "axes[0].set_title(\"Current Trend Over Time\")\n",
    "axes[0].legend(title=\"Node / Run\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"voltage_V\", hue=\"node\", style=\"run\", linewidth=2, ax=axes[1])\n",
    "axes[1].set_ylabel(\"Voltage (V)\")\n",
    "axes[1].set_title(\"Voltage Trend Over Time\")\n",
    "axes[1].set_xlabel(\"Timestamp\")\n",
    "axes[1].legend(title=\"Node / Run\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Findings\n",
    "\n",
    "Based on the visualizations and statistical analysis, we can derive the following insights:\n",
    "\n",
    "- The power consumption varies across different nodes and runs.\n",
    "- The cumulative energy consumption follows an increasing trend over time.\n",
    "- Voltage and current appear stable with minor fluctuations.\n",
    "\n",
    "Further analysis could involve:\n",
    "- Identifying periods of peak energy usage.\n",
    "- Comparing nodes to find efficiency variations.\n",
    "- Investigating external factors influencing power consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
