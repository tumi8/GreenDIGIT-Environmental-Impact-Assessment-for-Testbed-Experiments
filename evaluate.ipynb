{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Measurement Evaluation\n",
    "\n",
    "This notebook evaluates power consumption and energy trends from experiment results.  \n",
    "The data is collected from multiple nodes and analyzed for insights into power usage, voltage, and energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the Result Folder\n",
    "\n",
    "Before loading data, enter the path to your experiment result folder.  \n",
    "By default, the last used path is shown, but you can change it to any valid directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_result_folder = \"/srv/testbed/results/warmuth/default/\"\n",
    "default_result_folder = os.path.join(base_result_folder, \"2025-03-19_11-59-58_754222\")\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 1: Select Result Folder\n",
    "# -----------------------------------\n",
    "user_input = input(\n",
    "    f\"\\nEnter result folder path (leave empty to use default):\\n[{default_result_folder}]\\n> \"\n",
    ").strip()\n",
    "\n",
    "# Resolve path\n",
    "if not user_input:\n",
    "    RESULT_FOLDER = default_result_folder\n",
    "elif os.path.isabs(user_input):\n",
    "    RESULT_FOLDER = user_input\n",
    "else:\n",
    "    RESULT_FOLDER = os.path.join(base_result_folder, user_input)\n",
    "\n",
    "# Validate result folder\n",
    "if not os.path.exists(RESULT_FOLDER):\n",
    "    raise FileNotFoundError(f\"\\n[Error] Result folder does not exist:\\n{RESULT_FOLDER}\")\n",
    "\n",
    "print(f\"\\n[Info] Using result folder:\\n{RESULT_FOLDER}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 2: Detect Available Runs\n",
    "# -----------------------------------\n",
    "energy_folder = os.path.join(RESULT_FOLDER, \"energy\")\n",
    "available_runs = set()\n",
    "\n",
    "if os.path.exists(energy_folder):\n",
    "    for node in os.listdir(energy_folder):\n",
    "        node_path = os.path.join(energy_folder, node)\n",
    "        if os.path.isdir(node_path):\n",
    "            for filename in os.listdir(node_path):\n",
    "                if filename.endswith(\".csv\") and \"_run\" in filename:\n",
    "                    run_id = filename.split(\"_run\")[-1].split(\".\")[0]\n",
    "                    available_runs.add(run_id)\n",
    "\n",
    "available_runs = sorted(available_runs)\n",
    "\n",
    "if not available_runs:\n",
    "    raise ValueError(f\"\\n[Warning] No runs found in folder:\\n{energy_folder}\")\n",
    "\n",
    "print(f\"\\n[Info] Detected {len(available_runs)} run(s):\\n{', '.join(available_runs)}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 3: Select Runs to Load\n",
    "# -----------------------------------\n",
    "run_input = input(\"\\nEnter run numbers to include (comma-separated), or press Enter to include all:\\n> \").strip()\n",
    "\n",
    "if run_input:\n",
    "    selected_runs = {run.strip() for run in run_input.split(\",\")}\n",
    "    invalid_runs = selected_runs - set(available_runs)\n",
    "\n",
    "    if invalid_runs:\n",
    "        raise ValueError(\n",
    "            f\"\\n[Error] Invalid run(s) entered:\\n{', '.join(sorted(invalid_runs))}\"\n",
    "            f\"\\nAvailable runs:\\n{', '.join(available_runs)}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[Info] Filtering for {len(selected_runs)} run(s):\\n{', '.join(sorted(selected_runs))}\")\n",
    "else:\n",
    "    selected_runs = None\n",
    "    print(\"\\n[Info] Including all available runs.\")\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 4: Detect and Select Nodes\n",
    "# -----------------------------------\n",
    "available_nodes = sorted([\n",
    "    node for node in os.listdir(energy_folder)\n",
    "    if os.path.isdir(os.path.join(energy_folder, node))\n",
    "])\n",
    "\n",
    "if not available_nodes:\n",
    "    raise ValueError(f\"\\n[Warning] No node directories found in:\\n{energy_folder}\")\n",
    "\n",
    "print(f\"\\n[Info] Detected {len(available_nodes)} node(s):\\n{', '.join(available_nodes)}\")\n",
    "\n",
    "node_input = input(\"\\nEnter node names to include (comma-separated),\\n or press Enter to include all:\\n> \").strip()\n",
    "\n",
    "if node_input:\n",
    "    selected_nodes = {n.strip() for n in node_input.split(\",\")}\n",
    "    invalid_nodes = selected_nodes - set(available_nodes)\n",
    "\n",
    "    if invalid_nodes:\n",
    "        raise ValueError(\n",
    "            f\"\\n[Error] Invalid node(s) entered:\\n{', '.join(sorted(invalid_nodes))}\"\n",
    "            f\"\\nAvailable nodes:\\n{', '.join(available_nodes)}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[Info] Filtering for {len(selected_nodes)} node(s):\\n{', '.join(sorted(selected_nodes))}\")\n",
    "else:\n",
    "    selected_nodes = None\n",
    "    print(\"\\n[Info] Including all available nodes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creator Information\n",
    "\n",
    "The following table presents details about the experiment's creator, extracted from the **RO-Crate metadata**.\n",
    "\n",
    "- **Name:** The name of the creator.\n",
    "- **ORCID:** A unique researcher identifier, linked to the official ORCID profile.\n",
    "- **Affiliation:** The institution the creator is affiliated with.\n",
    "- **Affiliation ROR:** A **Research Organization Registry (ROR) ID**, used for standard identification of research institutions.\n",
    "- **Affiliation URL:** A direct link to the institutionâ€™s website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_creator_info():\n",
    "    \"\"\"\n",
    "    Extracts all creators from the RO-Crate metadata JSON file.\n",
    "    Retrieves each creator's name, ORCID, and affiliation details.\n",
    "    \"\"\"\n",
    "    rocrate_path = os.path.join(RESULT_FOLDER, \"ro-crate-metadata.json\")\n",
    "    if not os.path.exists(rocrate_path):\n",
    "        raise FileNotFoundError(f\"RO-Crate metadata file not found: {rocrate_path}\")\n",
    "\n",
    "    with open(rocrate_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    creators = []\n",
    "    credit_url = \"https://www.elsevier.com/researcher/author/policies-and-guidelines/credit-author-statement\"\n",
    "\n",
    "    for item in metadata.get(\"@graph\", []):\n",
    "        if item.get(\"@type\") == \"Person\" and \"creator\" in item.get(\"tags\", []):\n",
    "            creator_info = {\n",
    "                \"Creator Name\": item.get(\"name\", \"Unknown\"),\n",
    "                \"ORCID\": item.get(\"@id\", \"Unknown\"),\n",
    "                \"Contribution (CRediT)\": (\n",
    "                    f'<a href={credit_url} target=\"_blank\">{item.get(\"description\", \"Not specified\")}</a>'\n",
    "                ),\n",
    "                \"Affiliation Name\": \"Unknown\",\n",
    "                \"Affiliation ROR\": \"Unknown\",\n",
    "                \"Affiliation URL\": \"Unknown\"\n",
    "            }\n",
    "\n",
    "            # Find affiliation\n",
    "            affiliation_id = item.get(\"affiliation\", {}).get(\"@id\", None)\n",
    "            if affiliation_id:\n",
    "                for org in metadata.get(\"@graph\", []):\n",
    "                    if org.get(\"@id\") == affiliation_id:\n",
    "                        creator_info[\"Affiliation Name\"] = org.get(\"name\", \"Unknown\")\n",
    "                        creator_info[\"Affiliation ROR\"] = org.get(\"@id\", \"Unknown\")\n",
    "                        creator_info[\"Affiliation URL\"] = org.get(\"url\", \"Unknown\")\n",
    "                        break\n",
    "\n",
    "            creators.append(creator_info)\n",
    "\n",
    "    return creators\n",
    "\n",
    "creator_data = load_creator_info()\n",
    "creator_df = pd.DataFrame(creator_data)\n",
    "\n",
    "def make_link(text, url):\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{text}</a>' if url != \"Unknown\" else \"Unknown\"\n",
    "\n",
    "creator_df[\"ORCID\"] = creator_df[\"ORCID\"].apply(lambda x: make_link(\"ORCID Profile\", x))\n",
    "creator_df[\"Affiliation ROR\"] = creator_df[\"Affiliation ROR\"].apply(lambda x: make_link(\"ROR ID\", x))\n",
    "creator_df[\"Affiliation URL\"] = creator_df[\"Affiliation URL\"].apply(lambda x: make_link(\"University Website\", x))\n",
    "\n",
    "html_table = creator_df.to_html(escape=False, index=False)\n",
    "styled_table = f\"\"\"\n",
    "<style>\n",
    "    table {{ width: 80%; border-collapse: collapse; margin: 20px 0; }}\n",
    "    th, td {{ padding: 8px 12px; border: 1px solid #ddd; text-align: left; }}\n",
    "    th {{ background-color: #f4f4f4; font-weight: bold; }}\n",
    "</style>\n",
    "{html_table}\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(styled_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Information & Topology Visualization\n",
    "\n",
    "Each experiment setup includes metadata about the participating nodes.  \n",
    "This section extracts details such as:\n",
    "- Node names\n",
    "- Links to the Testbed -> Entrypoint to Testbed\n",
    "- Fully Qualified Domain Names (FQDN)\n",
    "- Topology information (if available).\n",
    "\n",
    "If a **topology visualization** is provided in the RO-Crate metadata, it is linked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rocrate_metadata():\n",
    "    \"\"\"\n",
    "    Load and parse the RO-Crate metadata JSON file.\n",
    "    Extract node information and locate paths for hardware details and topology PDFs.\n",
    "    \"\"\"\n",
    "    rocrate_path = os.path.join(RESULT_FOLDER, \"ro-crate-metadata.json\")\n",
    "    if not os.path.exists(rocrate_path):\n",
    "        raise FileNotFoundError(f\"RO-Crate metadata file not found: {rocrate_path}\")\n",
    "\n",
    "    with open(rocrate_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    nodes_info = []\n",
    "\n",
    "    for item in metadata.get(\"@graph\", []):\n",
    "        if \"tags\" in item and \"node\" in item[\"tags\"]:\n",
    "            node_name = item.get(\"name\", \"Unknown\")\n",
    "            fqdn = item.get(\"fqdn\", \"Unknown\")\n",
    "\n",
    "            topology_pdf_path = None\n",
    "            if isinstance(item.get(\"visualizedTopology\", {}), dict) and \"@id\" in item[\"visualizedTopology\"]:\n",
    "                topology_pdf_path = os.path.join(RESULT_FOLDER, item[\"visualizedTopology\"][\"@id\"])\n",
    "                print(topology_pdf_path)\n",
    "                if not os.path.exists(topology_pdf_path):\n",
    "                    topology_pdf_path = None\n",
    "\n",
    "            hardware_json_path = None\n",
    "            if isinstance(item.get(\"hardware\", {}), dict) and \"@id\" in item[\"hardware\"]:\n",
    "                hardware_json_path = os.path.join(RESULT_FOLDER, item[\"hardware\"][\"@id\"])\n",
    "                print(hardware_json_path)\n",
    "                if not os.path.exists(hardware_json_path):\n",
    "                    hardware_json_path = None\n",
    "\n",
    "            nodes_info.append({\n",
    "                \"name\": node_name if isinstance(node_name, str) else \"Unknown\",\n",
    "                \"fqdn\": fqdn if isinstance(fqdn, str) else \"Unknown\",\n",
    "                \"topology_pdf\": topology_pdf_path if topology_pdf_path else \"None\",\n",
    "                \"hardware_json\": hardware_json_path if hardware_json_path else \"None\"\n",
    "            })\n",
    "\n",
    "    return nodes_info\n",
    "\n",
    "def extract_hardware_info(hardware_json_path):\n",
    "    \"\"\"\n",
    "    Extract CPU, memory, and NIC info from the given hardware.json file.\n",
    "    Handles multiple CPUs and formats output for display. Robust to missing or None values.\n",
    "    \"\"\"\n",
    "    if not hardware_json_path or not os.path.exists(hardware_json_path):\n",
    "        return {\n",
    "            \"cpu_model\": \"Unknown\", \"cpu_cores\": \"Unknown\", \"cpu_threads\": \"Unknown\",\n",
    "            \"memory\": \"Unknown\", \"nic_models\": \"Unknown\"\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        with open(hardware_json_path, \"r\") as f:\n",
    "            hardware_data = json.load(f)\n",
    "\n",
    "        # CPU(s)\n",
    "        cpus = hardware_data.get(\"processor\", [])\n",
    "        cpu_models = [str(cpu.get(\"model\") or \"Unknown\") for cpu in cpus]\n",
    "        cpu_cores = [str(cpu.get(\"cores\") or \"Unknown\") for cpu in cpus]\n",
    "        cpu_threads = [str(cpu.get(\"threads\") or \"Unknown\") for cpu in cpus]\n",
    "\n",
    "        cpu_model_str = \", \".join(cpu_models)\n",
    "        cpu_cores_str = \", \".join(cpu_cores)\n",
    "        cpu_threads_str = \", \".join(cpu_threads)\n",
    "\n",
    "        # Memory\n",
    "        memory_info = hardware_data.get(\"memory\", {})\n",
    "        mem_val = memory_info.get(\"installed_capacity_human_val\", \"Unknown\")\n",
    "        mem_unit = memory_info.get(\"installed_capacity_human_unit\", \"\")\n",
    "        memory_str = f\"RAM: {mem_val} {mem_unit}\".strip() if mem_val != \"Unknown\" else \"Unknown\"\n",
    "\n",
    "        # NICs\n",
    "        nic_models = []\n",
    "        for nic in hardware_data.get(\"network\", []):\n",
    "            if isinstance(nic, dict):\n",
    "                nic_model = nic.get(\"model\")\n",
    "                if nic_model:\n",
    "                    nic_models.append(str(nic_model))\n",
    "        nic_str = \"<br>\".join(nic_models) if nic_models else \"No NICs detected\"\n",
    "\n",
    "        return {\n",
    "            \"cpu_model\": cpu_model_str,\n",
    "            \"cpu_cores\": cpu_cores_str,\n",
    "            \"cpu_threads\": cpu_threads_str,\n",
    "            \"memory\": memory_str,\n",
    "            \"nic_models\": nic_str\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to parse hardware.json: {e}\")\n",
    "        return {\n",
    "            \"cpu_model\": \"Unknown\", \"cpu_cores\": \"Unknown\", \"cpu_threads\": \"Unknown\",\n",
    "            \"memory\": \"Unknown\", \"nic_models\": \"Unknown\"\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# Load node metadata and hardware details\n",
    "nodes_info = load_rocrate_metadata()\n",
    "nodes_df = pd.DataFrame(nodes_info)\n",
    "hardware_details = [extract_hardware_info(node[\"hardware_json\"]) for node in nodes_info]\n",
    "hardware_df = pd.DataFrame(hardware_details)\n",
    "nodes_df = pd.concat([nodes_df, hardware_df], axis=1)\n",
    "nodes_df.drop(columns=[\"hardware_json\"], inplace=True)\n",
    "\n",
    "def extract_testbed(fqdn):\n",
    "    parts = fqdn.split(\".\")\n",
    "    if len(parts) > 1:\n",
    "        return parts[1].capitalize()\n",
    "\n",
    "nodes_df[\"Testbed Entrypoint\"] = nodes_df[\"fqdn\"].apply(extract_testbed)\n",
    "\n",
    "testbed_urls = {\n",
    "    \"Baltikum\": \"https://kaunas.net.cit.tum.de/\",\n",
    "    \"Blockchain\": \"https://coinbase.net.cit.tum.de/\"\n",
    "}\n",
    "\n",
    "def make_testbed_link(testbed):\n",
    "    url = testbed_urls.get(testbed, \"Unknown\")\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{testbed}</a>' if url != \"Unknown\" else \"Unknown\"\n",
    "\n",
    "nodes_df[\"Testbed Entrypoint\"] = nodes_df[\"Testbed Entrypoint\"].apply(make_testbed_link)\n",
    "\n",
    "def make_clickable(path):\n",
    "    return f'<a href=\"{path}\" target=\"_blank\">Open PDF</a>' if path != \"None\" else \"No topology available\"\n",
    "\n",
    "nodes_df[\"topology_pdf\"] = nodes_df[\"topology_pdf\"].apply(make_clickable)\n",
    "\n",
    "# Rename columns for better readability\n",
    "nodes_df.rename(columns={\n",
    "    \"name\": \"Name\",\n",
    "    \"fqdn\": \"FQDN\",\n",
    "    \"topology_pdf\": \"Topology\",\n",
    "    \"cpu_model\": \"CPU\",\n",
    "    \"cpu_cores\": \"Cores\",\n",
    "    \"cpu_threads\": \"Threads\",\n",
    "    \"memory\": \"Memory\",\n",
    "    \"nic_models\": \"NICs\",\n",
    "    \"Testbed\": \"Testbed\"\n",
    "}, inplace=True)\n",
    "\n",
    "nodes_df = nodes_df[[\"Name\", \"FQDN\", \"Testbed Entrypoint\", \"Topology\", \"CPU\", \"Cores\", \"Threads\", \"Memory\", \"NICs\"]]\n",
    "\n",
    "html_table = nodes_df.to_html(escape=False)\n",
    "styled_table = f\"\"\"\n",
    "<style>\n",
    "    table {{ width: 90%; border-collapse: collapse; margin: 20px 0; }}\n",
    "    th, td {{ padding: 8px 12px; border: 1px solid #ddd; text-align: left; }}\n",
    "    th {{ background-color: #f4f4f4; font-weight: bold; }}\n",
    "</style>\n",
    "{html_table}\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(styled_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Previewing Data\n",
    "\n",
    "The energy measurement data is stored in CSV format, with each node having its own folder inside the `energy` directory.\n",
    "\n",
    "The dataset includes:\n",
    "- **Timestamp** (`timestamp`): Time when the measurement was recorded.\n",
    "- **Current** (`current_mA`): Measured current in milliamps (mA).\n",
    "- **Voltage** (`voltage_V`): Measured voltage in volts (V).\n",
    "- **Power Consumption** (`power_active_W`): Active power in watts (W).\n",
    "- **Energy Counter** (`energy_counter_Wh`): Cumulative energy usage in watt-hours (Wh).\n",
    "\n",
    "Below, we load the data and display a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "\n",
    "def load_energy_data(selected_runs=None):\n",
    "    \"\"\"\n",
    "    Load and merge energy measurement data from CSV files.\n",
    "    If values are split into *_0, *_1 (e.g., current_mA_0, current_mA_1), they are summed into a unified column.\n",
    "    \"\"\"\n",
    "    energy_folder = os.path.join(RESULT_FOLDER, \"energy\")\n",
    "    if not os.path.exists(energy_folder):\n",
    "        raise FileNotFoundError(f\"Energy folder not found: {energy_folder}\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for node in os.listdir(energy_folder):\n",
    "        if selected_nodes and node not in selected_nodes:\n",
    "            continue\n",
    "        node_path = os.path.join(energy_folder, node)\n",
    "        if os.path.isdir(node_path):\n",
    "            for file in os.listdir(node_path):\n",
    "                if file.endswith(\".csv\") and \"_run\" in file:\n",
    "                    run_id = file.split(\"_run\")[-1].split(\".\")[0]\n",
    "                    if selected_runs is not None and run_id not in selected_runs:\n",
    "                        continue\n",
    "                    file_path = os.path.join(node_path, file)\n",
    "                    print(file_path)\n",
    "\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y%m%d%H%M%S%f\")\n",
    "                    df[\"node\"] = node\n",
    "                    df[\"run\"] = run_id\n",
    "\n",
    "                    # Auto-detect and merge *_0 + *_1 columns\n",
    "                    cols = df.columns\n",
    "                    metric_prefixes = set()\n",
    "                    for col in cols:\n",
    "                        if col.endswith(\"_0\") or col.endswith(\"_1\"):\n",
    "                            metric_prefixes.add(col.rsplit(\"_\", 1)[0])\n",
    "\n",
    "                    for prefix in metric_prefixes:\n",
    "                        col_0 = f\"{prefix}_0\"\n",
    "                        col_1 = f\"{prefix}_1\"\n",
    "                        if col_0 in df.columns and col_1 in df.columns:\n",
    "                            df[prefix] = df[col_0] + df[col_1]\n",
    "                            df.drop([col_0, col_1], axis=1, inplace=True)\n",
    "\n",
    "                    all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid CSV files found in the energy folder.\")\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "df = load_energy_data(selected_runs)\n",
    "\n",
    "def remove_outliers(df):\n",
    "    \"\"\"\n",
    "    Removes extreme outliers from all numeric columns using the IQR method.\n",
    "    \"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = remove_outliers(df)\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Set of Statistical Evaluations\n",
    "\n",
    "After loading the data, the notebook performs a standard set of statistical evaluations  \n",
    "to understand the structure and integrity of the dataset. This includes:\n",
    "\n",
    "- Summary statistics of numerical columns  \n",
    "- Detection of missing values  \n",
    "- Identification of outliers or unusual value ranges  \n",
    "- Checks for consistency across runs and nodes  \n",
    "\n",
    "These steps support further analysis by providing insights into data quality and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.drop(columns=['node', 'run'])\n",
    "display(temp_df.describe(exclude=[np.datetime64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Energy Consumption\n",
    "\n",
    "The `energy_counter_mWh` tracks the cumulative energy consumed over time, converted from watt-hours to milliwatt-hours (mWh).  \n",
    "This line plot shows how each node's energy consumption grows throughout the experiment, offering a clear comparison of power usage trends between nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Total Corrected Energy Consumption Per Node\n",
    "# - Aggregates total energy used per node, per run.\n",
    "# - Handles resets: if a counter drops mid-run, uses last value only.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def compute_corrected_energy(df):\n",
    "    \"\"\"\n",
    "    Computes total corrected energy per node/run, accounting for resets.\n",
    "    \"\"\"\n",
    "    corrected_energy = []\n",
    "\n",
    "    for (node, run), group in df.groupby([\"node\", \"run\"]):\n",
    "        first_value = group[\"energy_counter_Wh\"].iloc[0]\n",
    "        last_value = group[\"energy_counter_Wh\"].iloc[-1]\n",
    "\n",
    "        if (group[\"energy_counter_Wh\"].diff() < 0).any():\n",
    "            energy_used = last_value  # Reset occurred-> use only last\n",
    "        else:\n",
    "            energy_used = last_value - first_value\n",
    "\n",
    "        corrected_energy.append({\n",
    "            \"node\": node,\n",
    "            \"run\": run,\n",
    "            \"energy_used\": energy_used\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(corrected_energy)\n",
    "\n",
    "# Prepare data\n",
    "df_corrected = compute_corrected_energy(df)\n",
    "df_grouped = df_corrected.groupby(\"node\")[\"energy_used\"].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Use seaborn barplot with automatic color assignment\n",
    "sns.barplot(\n",
    "    data=df_grouped,\n",
    "    x=\"node\",\n",
    "    y=\"energy_used\",\n",
    "    hue=\"node\",\n",
    "    palette=\"pastel\",\n",
    "    dodge=False,\n",
    "    legend=False,\n",
    "    width=0.5  # thinner bars\n",
    ")\n",
    "\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for index, row in df_grouped.iterrows():\n",
    "    plt.text(index, row.energy_used + 0.01, f\"{row.energy_used:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Total Corrected Energy (Wh)\")\n",
    "plt.xlabel(\"Node\")\n",
    "plt.title(\"Total Corrected Energy Consumption Per Node\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Consumption Over Time\n",
    "\n",
    "The following plot shows the power consumption trends over time for different nodes.  \n",
    "This helps us observe variations in power usage and detect potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Plots Instantaneous Power Consumption (in Watts) over time\n",
    "# (uses absolute timestamps on the x-axis)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"power_active_W\", hue=\"node\", linewidth=2)\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Power Consumption (W)\")\n",
    "plt.title(\"Power Consumption Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Plots Instantaneous Power Consumption (in Watts) over relative time\n",
    "# (x-axis is seconds since the experiment started)\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "df[\"timestamp_relative\"] = (df[\"timestamp\"] - df[\"timestamp\"].min()).dt.total_seconds()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp_relative\", y=\"power_active_W\", hue=\"node\", linewidth=2)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Power Consumption (W)\")\n",
    "plt.title(\"Power Consumption Over Time (Relative)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Energy Consumption\n",
    "\n",
    "The energy counter represents the cumulative energy consumed over time.  \n",
    "This plot provides insights into the total energy usage per node and how it changes over the experiment duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Plots Cumulative Energy Consumption in mWh\n",
    "# (merged over all runs, grouped by node)\n",
    "# -----------------------------------------------\n",
    "\n",
    "df[\"energy_counter_mWh\"] = df[\"energy_counter_Wh\"] * 1000\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    x=\"timestamp\",\n",
    "    y=\"energy_counter_mWh\",\n",
    "    hue=\"node\",\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Cumulative Energy (mWh)\")\n",
    "plt.title(\"Cumulative Energy Consumption Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current and Voltage Trends\n",
    "\n",
    "To better understand the electrical characteristics, we visualize:\n",
    "- **Current (mA) over time** to see how power draw fluctuates.\n",
    "- **Voltage (V) over time** to ensure stability across measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Plots Current (mA) over Time\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "first_timestamps = df.groupby(\"run\")[\"timestamp\"].min()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"current_mA\", hue=\"node\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Current (mA)\")\n",
    "plt.title(\"Current Trend Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Mark run start times\n",
    "# ylim = plt.ylim()\n",
    "# text_ypos = ylim[0] - (ylim[1] - ylim[0]) * 0.03  # 3% below plot bottom\n",
    "\n",
    "# for run, ts in first_timestamps.items():\n",
    "#     plt.axvline(x=ts, color=\"black\", linestyle=\"dashed\", alpha=0.4)\n",
    "#     plt.text(ts, text_ypos, f\"Run {run}\", rotation=90, fontsize=9, color=\"black\",\n",
    "#              verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Plots Smoothed Voltage (V) over Time\n",
    "# Rolling mean is applied over a window of 5 samples\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "df[\"voltage_V_smoothed\"] = df[\"voltage_V\"].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"voltage_V_smoothed\", hue=\"node\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Voltage (V)\")\n",
    "plt.title(\"Voltage Trend Over Time (Smoothed)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Mark run start times\n",
    "# ylim = plt.ylim()\n",
    "# text_ypos = ylim[0] - (ylim[1] - ylim[0]) * 0.03\n",
    "\n",
    "# for run, ts in first_timestamps.items():\n",
    "#     plt.axvline(x=ts, color=\"black\", linestyle=\"dashed\", alpha=0.4)\n",
    "#     plt.text(ts, text_ypos, f\"Run {run}\", rotation=90, fontsize=9, color=\"black\",\n",
    "#              verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Consumption Rate Over Time\n",
    "\n",
    "This plot shows the **rate at which energy is consumed over time (mW/s)**.  \n",
    "Instead of cumulative energy, this visualization helps identify **periods of high workload**.  \n",
    "A higher energy rate means that the system was **actively consuming more power**,  \n",
    "which may indicate high CPU load or network traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Raw Energy Counter Over Time Plot\n",
    "# - Shows raw, unprocessed energy counter values in Wh.\n",
    "# - Useful for identifying resets or measurement inconsistencies.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for node, group in df.groupby(\"node\"):\n",
    "    plt.plot(group[\"timestamp\"], group[\"energy_counter_Wh\"], label=node, marker=\"o\", linestyle=\"-\")\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Energy Counter (Wh)\")\n",
    "plt.title(\"Energy Counter Over Time (Raw Data)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Energy Consumption Rate (mW/s) - Corrected\n",
    "# - Computes instantaneous energy rate from counter differences.\n",
    "# - Handles counter resets by forward-filling previous values.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "df[\"energy_diff\"] = df[\"energy_counter_Wh\"].diff()\n",
    "df[\"energy_adjusted\"] = df[\"energy_counter_Wh\"]\n",
    "df.loc[df[\"energy_diff\"] < 0, \"energy_adjusted\"] = np.nan  # Mark resets\n",
    "\n",
    "df[\"energy_adjusted\"] = df[\"energy_adjusted\"].ffill()  # Forward-fill resets\n",
    "df[\"energy_corrected_diff\"] = df[\"energy_adjusted\"].diff()\n",
    "df[\"energy_rate_mW\"] = (df[\"energy_corrected_diff\"] * 1000) / df[\"timestamp\"].diff().dt.total_seconds()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=\"timestamp\", y=\"energy_rate_mW\", hue=\"node\", linewidth=2)\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Energy Consumption Rate (mW/s)\")\n",
    "plt.title(\"Rate of Energy Consumption Over Time (Corrected)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Findings\n",
    "\n",
    "Based on the visualizations and statistical analysis, we can derive the following insights:\n",
    "\n",
    "- The power consumption varies across different nodes and runs.\n",
    "- The cumulative energy consumption follows an increasing trend over time.\n",
    "- Voltage and current appear stable with minor fluctuations.\n",
    "\n",
    "Further analysis could involve:\n",
    "- Identifying periods of peak energy usage.\n",
    "- Comparing nodes to find efficiency variations.\n",
    "- Investigating external factors influencing power consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
