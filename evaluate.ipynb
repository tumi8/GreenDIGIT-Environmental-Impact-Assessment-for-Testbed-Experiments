{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Energy Measurement Evaluation\n",
    "\n",
    "This notebook evaluates power consumption and energy trends from experiment results.  \n",
    "The data is collected from multiple nodes and analyzed for insights into power usage, voltage, and energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Set, Optional\n",
    "\n",
    "# ----------------------------- #\n",
    "# CONFIGURATION & SETUP\n",
    "# ----------------------------- #\n",
    "BASE_RESULT_FOLDER = \"/srv/testbed/results/warmuth/default/\"\n",
    "DEFAULT_SUBFOLDER = \"2025-03-19_11-59-58_754222\"\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "# INPUT AND UI UTILITIES\n",
    "# ----------------------------- #\n",
    "def get_user_input(prompt: str, default: str) -> str:\n",
    "    \"\"\"Prompt user input with a default fallback.\"\"\"\n",
    "    try:\n",
    "        user_input = input(f\"{prompt}\\n[{default}]\\n> \").strip()\n",
    "        return user_input or default\n",
    "    except Exception:\n",
    "        print(\"[Warning] Failed to read user input, using default.\")\n",
    "        return default\n",
    "\n",
    "\n",
    "def make_link(text: str, url: str) -> str:\n",
    "    \"\"\"Generate an HTML link or fallback to plain text.\"\"\"\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{text}</a>' if url != \"Unknown\" else \"Unknown\"\n",
    "\n",
    "\n",
    "def make_clickable(path: str) -> str:\n",
    "    \"\"\"Make a local file path clickable as an HTML link.\"\"\"\n",
    "    return f'<a href=\"{path}\" target=\"_blank\">Open PDF</a>' if path != \"None\" else \"No topology available\"\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "# FOLDER AND RUN HANDLING\n",
    "# ----------------------------- #\n",
    "def resolve_result_folder() -> str:\n",
    "    \"\"\"Resolve and validate the result folder path.\"\"\"\n",
    "    default_path = os.path.join(BASE_RESULT_FOLDER, DEFAULT_SUBFOLDER)\n",
    "    result_folder = get_user_input(\"Enter result folder path (leave empty to use default):\", default_path)\n",
    "    if not os.path.isabs(result_folder):\n",
    "        result_folder = os.path.join(BASE_RESULT_FOLDER, result_folder)\n",
    "    if not os.path.exists(result_folder):\n",
    "        raise FileNotFoundError(f\"Result folder does not exist: {result_folder}\")\n",
    "    print(f\"[Info] Using result folder:\\n{result_folder}\")\n",
    "    return result_folder\n",
    "\n",
    "\n",
    "def detect_runs(energy_folder: str) -> List[str]:\n",
    "    \"\"\"Detect available run IDs based on CSV filenames in the energy folder.\"\"\"\n",
    "    runs = set()\n",
    "    for node in os.listdir(energy_folder):\n",
    "        node_path = os.path.join(energy_folder, node)\n",
    "        if os.path.isdir(node_path):\n",
    "            for f in os.listdir(node_path):\n",
    "                if f.endswith(\".csv\") and \"_run\" in f:\n",
    "                    run_id = f.split(\"_run\")[-1].split(\".\")[0]\n",
    "                    runs.add(run_id)\n",
    "    return sorted(runs)\n",
    "\n",
    "\n",
    "def select_from_list(available_items: List[str], label: str) -> Set[str]:\n",
    "    \"\"\"Prompt user to select items from a list.\"\"\"\n",
    "    print(f\"Available {label}:\\n{', '.join(available_items)}\")\n",
    "    user_input = get_user_input(f\"Enter {label} to include (comma-separated), or press Enter to include all:\", \"\")\n",
    "    if not user_input:\n",
    "        return set(available_items)\n",
    "    selected = {x.strip() for x in user_input.split(',')}\n",
    "    invalid = selected - set(available_items)\n",
    "    if invalid:\n",
    "        raise ValueError(f\"Invalid {label} entered: {', '.join(invalid)}\")\n",
    "    return selected\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "# RO-CRATE PARSER\n",
    "# ----------------------------- #\n",
    "class ROCrateParser:\n",
    "    \"\"\"Class to parse metadata from a RO-Crate JSON structure.\"\"\"\n",
    "\n",
    "    def __init__(self, metadata_path: str):\n",
    "        self.metadata = self._load_json(metadata_path)\n",
    "\n",
    "    def _load_json(self, path: str) -> dict:\n",
    "        \"\"\"Load and return a JSON object from a file path.\"\"\"\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            print(f\"[Error] Failed to load JSON from {path}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_creators(self) -> List[Dict]:\n",
    "        \"\"\"Extract and format creator information.\"\"\"\n",
    "        creators = []\n",
    "        credit_url = \"https://www.elsevier.com/researcher/author/policies-and-guidelines/credit-author-statement\"\n",
    "        for item in self.metadata.get(\"@graph\", []):\n",
    "            if item.get(\"@type\") == \"Person\" and \"creator\" in item.get(\"tags\", []):\n",
    "                description = item.get(\"description\", \"Unknown\")\n",
    "                contribution_link = make_link(description, credit_url) if description != \"Unknown\" else \"Unknown\"\n",
    "                aff = item.get(\"affiliation\", {}).get(\"@id\", None)\n",
    "\n",
    "                affiliation_info = {\"Affiliation Name\": \"Unknown\", \"Affiliation ROR\": \"Unknown\", \"Affiliation URL\": \"Unknown\"}\n",
    "                if aff:\n",
    "                    for org in self.metadata.get(\"@graph\", []):\n",
    "                        if org.get(\"@id\") == aff:\n",
    "                            affiliation_info = {\n",
    "                                \"Affiliation Name\": org.get(\"name\", \"Unknown\"),\n",
    "                                \"Affiliation ROR\": make_link(\"ROR ID\", org.get(\"@id\", \"Unknown\")),\n",
    "                                \"Affiliation URL\": make_link(\"Website\", org.get(\"url\", \"Unknown\"))\n",
    "                            }\n",
    "                            break\n",
    "\n",
    "                creators.append({\n",
    "                    \"Creator Name\": item.get(\"name\", \"Unknown\"),\n",
    "                    \"ORCID\": make_link(\"ORCID Profile\", item.get(\"@id\", \"Unknown\")),\n",
    "                    \"Contribution (CRediT)\": contribution_link,\n",
    "                    **affiliation_info\n",
    "                })\n",
    "        return creators\n",
    "\n",
    "    def extract_nodes(self, result_folder: str) -> List[Dict]:\n",
    "        \"\"\"Extract node-level metadata including attached hardware and topologies.\"\"\"\n",
    "        nodes = []\n",
    "        for item in self.metadata.get(\"@graph\", []):\n",
    "            if \"tags\" in item and \"node\" in item[\"tags\"]:\n",
    "                node = {\n",
    "                    \"name\": item.get(\"name\", \"Unknown\"),\n",
    "                    \"fqdn\": item.get(\"fqdn\", \"Unknown\"),\n",
    "                    \"topology_pdf\": \"None\",\n",
    "                    \"hardware_json\": \"None\"\n",
    "                }\n",
    "                for key, local_key in [(\"visualizedTopology\", \"topology_pdf\"), (\"hardware\", \"hardware_json\")]:\n",
    "                    obj_id = item.get(key, {}).get(\"@id\")\n",
    "                    if obj_id:\n",
    "                        path = os.path.join(result_folder, obj_id)\n",
    "                        if os.path.exists(path):\n",
    "                            node[local_key] = path\n",
    "                nodes.append(node)\n",
    "        return nodes\n",
    "\n",
    "    def extract_hardware_info(self, path: str) -> Dict:\n",
    "        \"\"\"Extract hardware information from a JSON file.\"\"\"\n",
    "        if not path or not os.path.exists(path):\n",
    "            return {k: \"Unknown\" for k in [\"CPU\", \"Cores\", \"Threads\", \"Memory\", \"NICs\"]}\n",
    "        try:\n",
    "            data = self._load_json(path)\n",
    "            cpus = data.get(\"processor\", [])\n",
    "            cpu_model = \", \".join(cpu.get(\"model\", \"Unknown\") for cpu in cpus)\n",
    "            cores = \", \".join(str(cpu.get(\"cores\", \"Unknown\")) for cpu in cpus)\n",
    "            threads = \", \".join(str(cpu.get(\"threads\", \"Unknown\")) for cpu in cpus)\n",
    "            mem = data.get(\"memory\", {})\n",
    "            mem_str = f\"{mem.get('installed_capacity_human_val', 'Unknown')} {mem.get('installed_capacity_human_unit', '')}\".strip()\n",
    "            nics = \"<br>\".join(n.get(\"model\", \"\") for n in data.get(\"network\", []) if isinstance(n, dict)) or \"No NICs detected\"\n",
    "            return {\"CPU\": cpu_model, \"Cores\": cores, \"Threads\": threads, \"Memory\": mem_str, \"NICs\": nics}\n",
    "        except Exception:\n",
    "            return {k: \"Unknown\" for k in [\"CPU\", \"Cores\", \"Threads\", \"Memory\", \"NICs\"]}\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "# ENERGY DATA LOADING\n",
    "# ----------------------------- #\n",
    "def load_energy_data_from_csv(result_folder: str, selected_nodes: Set[str], selected_runs: Set[str]) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess energy data from CSV files.\"\"\"\n",
    "    energy_folder = os.path.join(result_folder, \"energy\")\n",
    "    all_data = []\n",
    "    for node in os.listdir(energy_folder):\n",
    "        if selected_nodes and node not in selected_nodes:\n",
    "            continue\n",
    "        node_path = os.path.join(energy_folder, node)\n",
    "        if os.path.isdir(node_path):\n",
    "            for file in os.listdir(node_path):\n",
    "                if file.endswith(\".csv\") and \"_run\" in file:\n",
    "                    run_id = file.split(\"_run\")[-1].split(\".\")[0]\n",
    "                    if selected_runs and run_id not in selected_runs:\n",
    "                        continue\n",
    "                    df = pd.read_csv(os.path.join(node_path, file))\n",
    "                    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y%m%d%H%M%S%f\")\n",
    "                    df[\"node\"], df[\"run\"] = node, run_id\n",
    "                    df = merge_energy_channels(df)\n",
    "                    all_data.append(df)\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No valid CSV files found.\")\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "def load_energy_data(source: str = \"csv\", **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Dispatch loading logic based on source type.\"\"\"\n",
    "    if source == \"csv\":\n",
    "        return load_energy_data_from_csv(**kwargs)\n",
    "    raise ValueError(f\"Unsupported energy data source: {source}\")\n",
    "\n",
    "\n",
    "def merge_energy_channels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge _0/_1 columns into unified channel columns.\"\"\"\n",
    "    prefixes = {col.rsplit('_', 1)[0] for col in df.columns if col.endswith('_0') or col.endswith('_1')}\n",
    "    for prefix in prefixes:\n",
    "        col0, col1 = f\"{prefix}_0\", f\"{prefix}_1\"\n",
    "        if col0 in df.columns and col1 in df.columns:\n",
    "            df[prefix] = df[col0] + df[col1]\n",
    "            df.drop(columns=[col0, col1], inplace=True)\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers from all numeric columns using the IQR method.\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = filtered_df[col].quantile(0.25)\n",
    "        Q3 = filtered_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = (filtered_df[col] >= Q1 - 1.5 * IQR) & (filtered_df[col] <= Q3 + 1.5 * IQR)\n",
    "        filtered_df = filtered_df[mask]\n",
    "    return filtered_df\n",
    "\n",
    "def compute_corrected_energy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute energy usage for each (node, run), accounting for resets.\"\"\"\n",
    "    result = []\n",
    "    for (node, run), group in df.groupby([\"node\", \"run\"]):\n",
    "        first, last = group[\"energy_counter_Wh\"].iloc[0], group[\"energy_counter_Wh\"].iloc[-1]\n",
    "        used = last if (group[\"energy_counter_Wh\"].diff() < 0).any() else last - first\n",
    "        result.append({\"node\": node, \"run\": run, \"energy_used\": used})\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def preprocess_energy_data(df: pd.DataFrame, smoothing_window: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Adds derived columns needed for plotting\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"timestamp_relative\"] = (df[\"timestamp\"] - df[\"timestamp\"].min()).dt.total_seconds()\n",
    "    df[\"energy_counter_mWh\"] = df[\"energy_counter_Wh\"] * 1000\n",
    "    df[\"voltage_V_smoothed\"] = df[\"voltage_V\"].rolling(window=smoothing_window, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def compute_total_corrected_energy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Computes corrected energy per run and aggregates it per node.\"\"\"\n",
    "    df_corrected = compute_corrected_energy(df)\n",
    "    df_grouped = df_corrected.groupby(\"node\")[\"energy_used\"].sum().reset_index()\n",
    "    return df_grouped\n",
    "\n",
    "# ----------------------------- #\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ----------------------------- #\n",
    "def plot_bar_with_labels(data: pd.DataFrame, x: str, y: str, title: str, ylabel: str) -> plt.Figure:\n",
    "    \"\"\"Create a bar plot with numeric labels.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(data=data, x=x, y=y, hue=x, dodge=False, legend=False, ax=ax)\n",
    "    for index, row in data.iterrows():\n",
    "        ax.text(index, row[y] + 0.01, f\"{row[y]:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def plot_time_series(df: pd.DataFrame, x: str, y: str, hue: str, title: str, ylabel: str) -> plt.Figure:\n",
    "    \"\"\"Plot time series data grouped by hue.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.lineplot(data=df, x=x, y=y, hue=hue, linewidth=2, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(title=hue, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "def plot_raw_energy_counter(df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Plot raw energy counter data for each node.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for node, group in df.groupby(\"node\"):\n",
    "        ax.plot(group[\"timestamp\"], group[\"energy_counter_Wh\"], label=node, marker=\"o\")\n",
    "    ax.set_title(\"Raw Energy Counter Over Time\")\n",
    "    ax.set_xlabel(\"Timestamp\")\n",
    "    ax.set_ylabel(\"Energy (Wh)\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(title=\"Node\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "\n",
    "# ----------------------------- #\n",
    "# BASIC DATAFRAME DISPLAY HELPERS\n",
    "# ----------------------------- #\n",
    "def display_df_head_tail(df):\n",
    "    display(HTML(\"<h3>First Rows</h3>\"))\n",
    "    display(df.head())\n",
    "    display(HTML(\"<h3>Last Rows</h3>\"))\n",
    "    display(df.tail())\n",
    "\n",
    "def display_summary_statistics(df):\n",
    "    temp_df = df.drop(columns=['node', 'run'], errors='ignore')\n",
    "    stats = temp_df.describe(exclude=[np.datetime64])\n",
    "    display(HTML(\"<h3>Summary Statistics</h3>\"))\n",
    "    display(stats)\n",
    "\n",
    "# ----------------------------- #\n",
    "# STYLED HTML TABLE DISPLAY\n",
    "# ----------------------------- #\n",
    "def display_styled_html_table(df, width=\"90%\"):\n",
    "    html_table = df.to_html(escape=False, index=False)\n",
    "    styled_table = f\"\"\"\n",
    "    <style>\n",
    "        table {{\n",
    "            width: {width};\n",
    "            border-collapse: collapse;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        th, td {{\n",
    "            padding: 8px 12px;\n",
    "            border: 1px solid #ddd;\n",
    "            text-align: left;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #f4f4f4;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "    </style>\n",
    "    {html_table}\n",
    "    \"\"\"\n",
    "    display(HTML(styled_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Specify the Result Folder\n",
    "\n",
    "Before loading data, enter the path to your experiment result folder.  \n",
    "By default, the last used path is shown, but you can change it to any valid directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = resolve_result_folder()\n",
    "energy_folder = os.path.join(result_folder, \"energy\")\n",
    "\n",
    "runs = detect_runs(energy_folder)\n",
    "selected_runs = select_from_list(runs, \"run IDs\")\n",
    "\n",
    "nodes = sorted([d for d in os.listdir(energy_folder) if os.path.isdir(os.path.join(energy_folder, d))])\n",
    "selected_nodes = select_from_list(nodes, \"node names\")\n",
    "\n",
    "parser = ROCrateParser(os.path.join(result_folder, \"ro-crate-metadata.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Creator Information\n",
    "\n",
    "The following table presents details about the experiment's creator, extracted from the **RO-Crate metadata**.\n",
    "\n",
    "- **Name:** The name of the creator.\n",
    "- **ORCID:** A unique researcher identifier, linked to the official ORCID profile.\n",
    "- **Affiliation:** The institution the creator is affiliated with.\n",
    "- **Affiliation ROR:** A **Research Organization Registry (ROR) ID**, used for standard identification of research institutions.\n",
    "- **Affiliation URL:** A direct link to the institutionâ€™s website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator_df = pd.DataFrame(parser.extract_creators())\n",
    "display_styled_html_table(creator_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Node Information & Topology Visualization\n",
    "\n",
    "Each experiment setup includes metadata about the participating nodes.  \n",
    "This section extracts details such as:\n",
    "- Node names\n",
    "- Links to the Testbed -> Entrypoint to Testbed\n",
    "- Fully Qualified Domain Names (FQDN)\n",
    "- Topology information (if available).\n",
    "\n",
    "If a **topology visualization** is provided in the RO-Crate metadata, it is linked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_info = parser.extract_nodes(result_folder)\n",
    "hw_details = [parser.extract_hardware_info(n[\"hardware_json\"]) for n in nodes_info]\n",
    "\n",
    "df_nodes = pd.DataFrame(nodes_info).drop(columns=\"hardware_json\")\n",
    "df_hw = pd.DataFrame(hw_details)\n",
    "\n",
    "full_node_df = pd.concat([df_nodes, df_hw], axis=1)\n",
    "full_node_df[\"topology_pdf\"] = full_node_df[\"topology_pdf\"].apply(make_clickable)\n",
    "\n",
    "display_styled_html_table(full_node_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Loading and Previewing Data\n",
    "\n",
    "The energy measurement data is stored in CSV format, with each node having its own folder inside the `energy` directory.\n",
    "\n",
    "The dataset includes:\n",
    "- **Timestamp** (`timestamp`): Time when the measurement was recorded.\n",
    "- **Current** (`current_mA`): Measured current in milliamps (mA).\n",
    "- **Voltage** (`voltage_V`): Measured voltage in volts (V).\n",
    "- **Power Consumption** (`power_active_W`): Active power in watts (W).\n",
    "- **Energy Counter** (`energy_counter_Wh`): Cumulative energy usage in watt-hours (Wh).\n",
    "\n",
    "Below, we load the data and display a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_energy_data(\n",
    "    source='csv',\n",
    "    result_folder=result_folder,\n",
    "    selected_nodes=selected_nodes,\n",
    "    selected_runs=selected_runs\n",
    ")\n",
    "df = remove_outliers(df)\n",
    "\n",
    "display_df_head_tail(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Common Set of Statistical Evaluations\n",
    "\n",
    "After loading the data, the notebook performs a standard set of statistical evaluations  \n",
    "to understand the structure and integrity of the dataset. This includes:\n",
    "\n",
    "- Summary statistics of numerical columns  \n",
    "- Detection of missing values  \n",
    "- Identification of outliers or unusual value ranges  \n",
    "- Checks for consistency across runs and nodes  \n",
    "\n",
    "These steps support further analysis by providing insights into data quality and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary_statistics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Energy Data Visualizations\n",
    "\n",
    "This section presents several plots to help analyze the energy consumption behavior across different nodes and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_energy_data(df)\n",
    "df_grouped = compute_total_corrected_energy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Total Corrected Energy Consumption Per Node\n",
    "\n",
    "This bar plot shows the total energy consumed by each node across all selected experiment runs.\n",
    "The values are computed from the energy counter, with corrections to account for possible counter resets.\n",
    "It provides a straightforward comparison of total power usage per node during the observed workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_with_labels(df_grouped, \"node\", \"energy_used\", \"Total Corrected Energy Consumption Per Node\", \"Total Energy (Wh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Power Consumption Over Time\n",
    "\n",
    "The following plot shows the power consumption trends over time for different nodes.  \n",
    "This helps us observe variations in power usage and detect potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(df, \"timestamp\", \"power_active_W\", \"node\", \"Power Over Time\", \"Power (W)\")\n",
    "plot_time_series(df, \"timestamp_relative\", \"power_active_W\", \"node\", \"Relative Power Over Time\", \"Power (W)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Cumulative Energy Consumption\n",
    "\n",
    "The energy counter represents the cumulative energy consumed over time.  \n",
    "This plot provides insights into the total energy usage per node and how it changes over the experiment duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(df, \"timestamp\", \"energy_counter_mWh\", \"node\", \"Cumulative Energy\", \"Energy (mWh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Current and Voltage Trends\n",
    "\n",
    "To better understand the electrical characteristics, we visualize:\n",
    "- **Current (mA) over time** to see how power draw fluctuates.\n",
    "- **Voltage (V) over time** to ensure stability across measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(df, \"timestamp\", \"current_mA\", \"node\", \"Current Over Time\", \"Current (mA)\")\n",
    "plot_time_series(df, \"timestamp\", \"voltage_V_smoothed\", \"node\", \"Smoothed Voltage\", \"Voltage (V)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Energy Consumption Rate Over Time (TODO)\n",
    "\n",
    "This plot shows the **rate at which energy is consumed over time (mW/s)**.  \n",
    "Instead of cumulative energy, this visualization helps identify **periods of high workload**.  \n",
    "A higher energy rate means that the system was **actively consuming more power**,  \n",
    "which may indicate high CPU load or network traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raw_energy_counter(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
