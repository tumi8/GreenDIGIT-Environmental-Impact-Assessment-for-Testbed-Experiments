{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CPU Energy Model Construction Notebook**\n",
    "\n",
    "This notebook builds a server-specific energy model by analyzing stress experiment runs.  \n",
    "The aim is to estimate the **per-core power consumption** based on controlled workloads, and use this to form a predictive model for energy estimation.\n",
    "\n",
    "We assume:\n",
    "- Each experiment run uses a known number of CPU cores.\n",
    "- Power consumption is measured over time.\n",
    "- The base (idle) power consumption of the system is known or measured separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Constants ===\n",
    "POWER_COLUMN = \"power_active_W\"\n",
    "CPU_MODEL_FOLDER = \"data/cpu_models\"\n",
    "GPU_MODEL_FOLDER = \"data/gpu_models\"\n",
    "\n",
    "# === Build User Config ===\n",
    "def build_config(server_name=None, result_subfolder=None, idle_power=None, model_kind=None):\n",
    "    if not server_name:\n",
    "        server_name = input(\"Enter the server name (e.g., riga): \").strip()\n",
    "\n",
    "    if not result_subfolder:\n",
    "        result_subfolder = input(\"Enter the result subfolder name (e.g., 2024_stress_4_cores): \").strip()\n",
    "\n",
    "    if not model_kind:\n",
    "        model_kind = input(\"Model type? [cpu/gpu] (default: cpu): \").strip().lower() or \"cpu\"\n",
    "    if model_kind not in {\"cpu\", \"gpu\"}:\n",
    "        raise ValueError(\"model_kind must be 'cpu' or 'gpu'\")\n",
    "\n",
    "    try:\n",
    "        idle_power_input = input(\"Enter the idle power in watts (e.g., 58.0): \").strip()\n",
    "        idle_power = float(idle_power_input)\n",
    "    except ValueError:\n",
    "        print(\"Invalid number. Please enter a valid float value (e.g., 58.0).\")\n",
    "        raise\n",
    "\n",
    "    base_result_path = os.path.join(\"/srv/testbed/results/warmuth/default\")\n",
    "    full_result_folder = os.path.join(base_result_path, result_subfolder)\n",
    "    if not os.path.exists(full_result_folder):\n",
    "        raise ValueError(f\"Warning: The folder {full_result_folder} does not exist.\")\n",
    "\n",
    "    # Defaults differ for cpu vs gpu\n",
    "    if model_kind == \"cpu\":\n",
    "        map_to = \"cores\"\n",
    "        model_output = \"cpu_model\"\n",
    "        x_col = \"cores\"\n",
    "    else:\n",
    "        map_to = \"gpu_load\"\n",
    "        model_output = \"gpu_model\"\n",
    "        x_col = \"gpu_load\"\n",
    "\n",
    "    return {\n",
    "        \"result_folder\": str(full_result_folder),\n",
    "        \"server_name\": server_name,\n",
    "        \"idle_power\": idle_power,\n",
    "        \"csv_base_name\": \"measurement_run\",\n",
    "        \"csv_extension\": \".csv\",\n",
    "        \"map_to\": map_to,\n",
    "        \"model_output\": model_output,\n",
    "        \"model_kind\": model_kind,\n",
    "        \"x_col\": x_col,\n",
    "        \"fix_idle\": False,\n",
    "\n",
    "        # GPU defaults: 25/50/75/100\n",
    "        \"gpu_load_levels\": [0.25, 0.50, 0.75, 1.00],\n",
    "    }\n",
    "\n",
    "# === Configuration Utilities ===\n",
    "def validate_config(config: Dict, required_keys: List[str]) -> None:\n",
    "    missing = [key for key in required_keys if key not in config]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required config keys: {missing}\")\n",
    "\n",
    "def get_csv_folder(config: Dict) -> str:\n",
    "    return os.path.join(config[\"result_folder\"], \"energy\", config[\"server_name\"])\n",
    "\n",
    "# === Data Loading and Processing ===\n",
    "def generate_run_mapping_cpu(config: Dict, fallback_cores: int = 4) -> Dict[str, int]:\n",
    "    if \"start_index\" not in config or \"end_index\" not in config:\n",
    "        cpu_info = load_cpu_info(config)\n",
    "        cores = cpu_info.get(\"cores\", fallback_cores)\n",
    "        config[\"start_index\"] = 0\n",
    "        config[\"end_index\"] = cores - 1\n",
    "\n",
    "    start = config[\"start_index\"]\n",
    "    end = config[\"end_index\"]\n",
    "    max_digits = len(str(end + 1))\n",
    "\n",
    "    mapping = {\n",
    "        f\"{config['csv_base_name']}{str(i).zfill(max_digits)}{config['csv_extension']}\": i + 1\n",
    "        for i in range(start, end + 1)\n",
    "    }\n",
    "    print(f\"Run mapping for '{config['map_to']}':\\n{json.dumps(mapping, indent=2)}\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def generate_run_mapping_gpu(config: Dict) -> Dict[str, float]:\n",
    "    # assumes runs 0..len(levels)-1 correspond to 25/50/75/100 in order\n",
    "    levels = config.get(\"gpu_load_levels\", [0.25, 0.50, 0.75, 1.00])\n",
    "    max_digits = len(str(len(levels)))\n",
    "\n",
    "    mapping = {\n",
    "        f\"{config['csv_base_name']}{str(i).zfill(max_digits)}{config['csv_extension']}\": float(level)\n",
    "        for i, level in enumerate(levels)\n",
    "    }\n",
    "    print(f\"Run mapping for '{config['map_to']}':\\n{json.dumps(mapping, indent=2)}\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def generate_run_mapping(config: Dict, fallback_cores: int = 4) -> Dict:\n",
    "    if config.get(\"model_kind\", \"cpu\") == \"gpu\":\n",
    "        return generate_run_mapping_gpu(config)\n",
    "    return generate_run_mapping_cpu(config, fallback_cores=fallback_cores)\n",
    "\n",
    "def merge_energy_channels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge _0/_1 columns into unified channel columns.\"\"\"\n",
    "    prefixes = {\n",
    "        col.rsplit('_', 1)[0]\n",
    "        for col in df.columns\n",
    "        if col.endswith('_0') or col.endswith('_1')\n",
    "    }\n",
    "    for prefix in prefixes:\n",
    "        col0, col1 = f\"{prefix}_0\", f\"{prefix}_1\"\n",
    "        if col0 in df.columns and col1 in df.columns:\n",
    "            df[prefix] = df[col0] + df[col1]\n",
    "            df.drop(columns=[col0, col1], inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_power_data(\n",
    "    csv_folder: str,\n",
    "    run_mapping: Dict[str, float],\n",
    "    p_base: float,\n",
    "    x_col: str,\n",
    "    model_kind: str,\n",
    "    power_column: str = POWER_COLUMN\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "    for filename, x_val in run_mapping.items():\n",
    "        path = os.path.join(csv_folder, filename)\n",
    "        df = pd.read_csv(path)\n",
    "        df = merge_energy_channels(df)\n",
    "        avg_power = float(df[power_column].mean())\n",
    "\n",
    "        row = {\n",
    "            \"filename\": filename,\n",
    "            x_col: float(x_val),\n",
    "            \"avg_power\": round(avg_power, 2),\n",
    "        }\n",
    "\n",
    "        # Optional: “per-unit” metric (kept for convenience / sanity checks)\n",
    "        if model_kind == \"cpu\":\n",
    "            cores = float(x_val)\n",
    "            row[\"per_unit_power\"] = round((avg_power - p_base) / cores, 2) if cores > 0 else np.nan\n",
    "        else:\n",
    "            load = float(x_val)\n",
    "            row[\"per_unit_power\"] = round((avg_power - p_base) / load, 2) if load > 0 else np.nan\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    print(f\"Loaded data for {len(results)} runs.\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# === Modeling ===\n",
    "def fit_models(\n",
    "    model_df: pd.DataFrame,\n",
    "    p_base: float,\n",
    "    x_col: str,\n",
    "    fix_idle: bool = False\n",
    ") -> Tuple[LinearRegression, LinearRegression, PolynomialFeatures]:\n",
    "    X = model_df[[x_col]]\n",
    "    y = model_df[\"avg_power\"]\n",
    "\n",
    "    if fix_idle:\n",
    "        reg_linear = LinearRegression(fit_intercept=False).fit(X, y - p_base)\n",
    "        model_df[\"predicted_linear\"] = reg_linear.predict(X) + p_base\n",
    "    else:\n",
    "        reg_linear = LinearRegression().fit(X, y)\n",
    "        model_df[\"predicted_linear\"] = reg_linear.predict(X)\n",
    "\n",
    "    model_df[\"error_linear\"] = (\n",
    "        (model_df[\"avg_power\"] - model_df[\"predicted_linear\"]).abs()\n",
    "        / model_df[\"avg_power\"] * 100\n",
    "    )\n",
    "\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "\n",
    "    if fix_idle:\n",
    "        reg_poly = LinearRegression(fit_intercept=False).fit(X_poly, y - p_base)\n",
    "        model_df[\"predicted_poly\"] = reg_poly.predict(X_poly) + p_base\n",
    "    else:\n",
    "        reg_poly = LinearRegression().fit(X_poly, y)\n",
    "        model_df[\"predicted_poly\"] = reg_poly.predict(X_poly)\n",
    "\n",
    "    model_df[\"error_poly\"] = (\n",
    "        (model_df[\"avg_power\"] - model_df[\"predicted_poly\"]).abs()\n",
    "        / model_df[\"avg_power\"] * 100\n",
    "    )\n",
    "\n",
    "    print(\"Model fitting complete.\")\n",
    "    return reg_linear, reg_poly, poly\n",
    "\n",
    "def predict_cpu_power_detailed(\n",
    "    per_core_loads: List[float],\n",
    "    per_core_powers: List[float],\n",
    "    p_base: float\n",
    ") -> float:\n",
    "    return p_base + sum(l * p for l, p in zip(per_core_loads, per_core_powers))\n",
    "\n",
    "# === Visualization ===\n",
    "def plot_predicted_load_levels(\n",
    "    num_cores: Optional[int] = None,\n",
    "    p_core: Optional[float] = None,\n",
    "    p_base: Optional[float] = None,\n",
    "    load_levels: Optional[List[float]] = None,\n",
    "    labels: Optional[List[str]] = None,\n",
    "    cpu_model: Optional[Dict] = None,\n",
    "    method: str = \"linear\",\n",
    "    per_core_steps: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot predicted total server power at different CPU load levels\n",
    "    or for each number of active cores.\n",
    "    \"\"\"\n",
    "    if cpu_model:\n",
    "        num_cores = cpu_model.get(\"cpu_info\", {}).get(\"cores\")\n",
    "\n",
    "    if num_cores is None:\n",
    "        raise ValueError(\"Missing 'num_cores' information.\")\n",
    "\n",
    "    if per_core_steps:\n",
    "        core_counts = list(range(1, num_cores + 1))\n",
    "        labels = [f\"{cores} cores\" for cores in core_counts]\n",
    "        predicted = []\n",
    "        for cores in core_counts:\n",
    "            if cpu_model:\n",
    "                predicted_power = predict_power(cpu_model, num_cores=cores, method=method)\n",
    "            else:\n",
    "                predicted_power = p_base + (p_core * cores)\n",
    "            predicted.append(predicted_power)\n",
    "    else:\n",
    "        load_levels = load_levels or [0.0, 0.25, 0.5, 1.0]\n",
    "        labels = labels or [f\"{int(load * 100)}% Load\" if load > 0 else \"Idle\" for load in load_levels]\n",
    "        predicted = []\n",
    "        for load in load_levels:\n",
    "            active_cores = num_cores * load\n",
    "            if cpu_model:\n",
    "                if active_cores == 0:\n",
    "                    predicted_power = cpu_model[\"linear_model\"][\"p_base\"]\n",
    "                else:\n",
    "                    predicted_power = predict_power(cpu_model, num_cores=active_cores, method=method)\n",
    "            else:\n",
    "                predicted_power = p_base + (p_core * active_cores)\n",
    "            predicted.append(predicted_power)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(labels, predicted, color=\"skyblue\", edgecolor=\"black\")\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, f\"{yval:.1f} W\",\n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "    title_mode = \"Per Core Steps @100% Load\" if per_core_steps else f\"{method.capitalize()} Model\"\n",
    "    plt.title(f\"Predicted Server Power ({title_mode})\")\n",
    "    plt.ylabel(\"Power (W)\")\n",
    "    plt.ylim(0, max(predicted) + 20)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_fit(\n",
    "    model_df: pd.DataFrame,\n",
    "    reg_linear: LinearRegression,\n",
    "    reg_poly: LinearRegression,\n",
    "    poly: PolynomialFeatures,\n",
    "    x_col: str = \"cores\"\n",
    ") -> None:\n",
    "    x_min = model_df[x_col].min()\n",
    "    x_max = model_df[x_col].max()\n",
    "\n",
    "    x_vals = pd.DataFrame({\n",
    "        x_col: np.linspace(x_min, x_max, 100)\n",
    "    })\n",
    "\n",
    "    y_linear = reg_linear.predict(x_vals)\n",
    "    y_poly = reg_poly.predict(poly.transform(x_vals))\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(data=model_df, x=x_col, y=\"avg_power\", s=80, label=\"Measured\")\n",
    "    plt.plot(x_vals[x_col], y_linear, color=\"red\", label=\"Linear Fit\", linewidth=2)\n",
    "    plt.plot(x_vals[x_col], y_poly, color=\"blue\", label=\"Polynomial Fit (Degree 2)\", linewidth=2)\n",
    "    plt.title(\"Measured Power vs. Model Predictions\")\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(\"Power (W)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_model_errors(model_df: pd.DataFrame) -> None:\n",
    "    display_df = model_df.copy()\n",
    "\n",
    "    display_df[\"error_linear\"] = display_df[\"error_linear\"].map(lambda x: f\"{x:.2f}%\")\n",
    "    display_df[\"error_poly\"] = display_df[\"error_poly\"].map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    for col in [\"cores\", \"avg_power\", \"predicted_linear\", \"predicted_poly\"]:\n",
    "        if col in display_df.columns:\n",
    "            display_df[col] = display_df[col].round(2)\n",
    "\n",
    "    display(display_df)\n",
    "\n",
    "# === Model Persistence ===\n",
    "def load_cpu_info(config: Dict) -> Dict:\n",
    "    path = os.path.join(config[\"result_folder\"], \"config\", config[\"server_name\"], \"hardware.json\")\n",
    "    with open(path, \"r\") as file:\n",
    "        hardware = json.load(file)\n",
    "        cpu = hardware.get(\"processor\", [{}])[0]\n",
    "        return {\"cores\": cpu.get(\"cores\"), \"model\": cpu.get(\"model\")}\n",
    "    return {}\n",
    "\n",
    "def load_gpu_info(config: Dict) -> Dict:\n",
    "    path = os.path.join(config[\"result_folder\"], \"config\", config[\"server_name\"], \"hardware.json\")\n",
    "    with open(path, \"r\") as f:\n",
    "        hardware = json.load(f)\n",
    "    gpus = hardware.get(\"graphics\", []) or []\n",
    "    by_model = {}\n",
    "    for g in gpus:\n",
    "        if not isinstance(g, dict):\n",
    "            continue\n",
    "        vendor = (g.get(\"vendor\") or \"Unknown\").strip()\n",
    "        model = (g.get(\"model\") or \"Unknown\").strip()\n",
    "        key = f\"{vendor} {model}\".strip()\n",
    "        by_model[key] = by_model.get(key, 0) + 1\n",
    "    return {\"count\": sum(by_model.values()), \"by_model\": by_model}\n",
    "\n",
    "\n",
    "def save_energy_model(\n",
    "    config: Dict,\n",
    "    p_unit: float,                 # p_core for cpu OR p_load for gpu\n",
    "    intercept: float,\n",
    "    poly_coeffs: Optional[Tuple[float, float, float]] = None,\n",
    "    mapping: Optional[Dict] = None,\n",
    "    cpu_info: Optional[Dict] = None,\n",
    "    gpu_info: Optional[Dict] = None,\n",
    ") -> Dict:\n",
    "    kind = config.get(\"model_kind\", \"cpu\")\n",
    "    out_folder = CPU_MODEL_FOLDER if kind == \"cpu\" else GPU_MODEL_FOLDER\n",
    "\n",
    "    output_name = f\"{config['model_output']}_{config['server_name']}.json\"\n",
    "    output_path = os.path.join(out_folder, output_name)\n",
    "\n",
    "    model = {\n",
    "        \"model_kind\": kind,\n",
    "        \"model_type\": \"linear_fixed_idle\" if config.get(\"fix_idle\") else \"linear_free_fit\",\n",
    "        \"linear_model\": {\n",
    "            \"p_base\": config[\"idle_power\"],\n",
    "            \"p_unit\": p_unit,               # cpu: W/core, gpu: W/(1.0 load)\n",
    "            \"fitted_intercept\": intercept\n",
    "        },\n",
    "        \"x_col\": config[\"x_col\"],           # \"cores\" or \"gpu_load\"\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"node_name\": config[\"server_name\"],\n",
    "        \"source_files\": mapping or {},\n",
    "        \"cpu_info\": cpu_info or {},\n",
    "        \"gpu_info\": gpu_info or {},\n",
    "    }\n",
    "\n",
    "    if poly_coeffs is not None:\n",
    "        a, b, c = poly_coeffs\n",
    "        model[\"polynomial_model\"] = {\"a\": a, \"b\": b, \"c\": c}\n",
    "\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(model, f, indent=2)\n",
    "    print(f\"Saved model to {output_path}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration\n",
    "\n",
    "The CONFIG dictionary defines the core setup for running a CPU power modeling experiment.  \n",
    "It controls where the data comes from, how the models are built, and where results are saved.\n",
    "\n",
    "### Configuration Fields\n",
    "\n",
    "| Key               | Type    | Description \n",
    "|------------------|---------|-------------\n",
    "| result_folder  | str   | Root path to the experiment results. This is used to locate CSV files (under energy/) and system metadata (hardware.json under config/). \n",
    "| server_name    | str   | Logical name or hostname of the test server. Used to build subpaths to results and metadata folders. \n",
    "| idle_power     | float | Idle (baseline) power consumption in watts. Used as a reference point to calculate per-core dynamic power. \n",
    "| csv_base_name  | str   | Prefix for measurement CSV filenames (e.g., measurement_run0.csv, measurement_run1.csv, ...). \n",
    "| csv_extension  | str   | File extension for the measurement files. Typically .csv. \n",
    "| map_to         | str   | Logical label for mapping measurements to a parameter (e.g., \"cores\" to track how many CPU cores were active). Mostly used in logging and plots. \n",
    "| model_output   | str   | Base filename for the saved CPU power model. Final output will be stored in the cpu_models/ folder as model_output_server_name.json. \n",
    "| fix_idle       | bool  | If True, forces the model to use a fixed intercept at idle_power. If False, the model fits the intercept freely based on data. \n",
    "\n",
    "\n",
    "### Additional Behavior\n",
    "\n",
    "- If start_index and end_index are not provided, they are automatically inferred from the number of CPU cores (based on hardware.json).\n",
    "- Models are saved as JSON files and include timestamps, node info, and fitted parameters.\n",
    "- Filenames for data are automatically constructed using {csv_base_name}{index}{csv_extension}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = build_config()\n",
    "run_mapping = generate_run_mapping(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Stress Run Data\n",
    "\n",
    "Each CSV file represents a stress run using a known number of CPU cores.  \n",
    "We compute the average power and derive the per-core contribution using:\n",
    "\n",
    "$$\n",
    "P_{\\text{core}} = \\frac{\\bar{P}_{\\text{measured}} - P_{\\text{base}}}{\\text{\\# active cores}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_folder = get_csv_folder(CONFIG)\n",
    "# model_df = load_power_data(csv_folder, run_mapping, CONFIG[\"idle_power\"])\n",
    "\n",
    "\n",
    "csv_folder = get_csv_folder(CONFIG)\n",
    "model_df = load_power_data(\n",
    "    csv_folder,\n",
    "    run_mapping,\n",
    "    CONFIG[\"idle_power\"],\n",
    "    x_col=CONFIG[\"x_col\"],\n",
    "    model_kind=CONFIG[\"model_kind\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "\n",
    "We fit two models to understand how CPU usage affects total power consumption:\n",
    "\n",
    "- **Linear Regression**: Assumes each core adds a constant amount of power.\n",
    "- **Polynomial Regression (Degree 2)**: Allows for non-linear effects like saturation or thermal throttling.\n",
    "\n",
    "The model is used in this generalized prediction formula:\n",
    "\n",
    "$$\n",
    "P_{\\text{server}} = P_{\\text{base}} + \\sum_{i=1}^{n} \\lambda_i \\cdot P_{\\text{core}, i} + \\sum_{j=1}^{k} \\lambda_j \\cdot P_{\\text{nic}, j}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $P_{\\text{server}}$: Total predicted server power (watts)  \n",
    "- $P_{\\text{base}}$: Idle power consumption of the server (measured)  \n",
    "- $n$: Number of active CPU cores  \n",
    "- $\\lambda_i$: Load factor (0–1) of CPU core $i$  \n",
    "- $P_{\\text{core}, i}$: Power used by CPU core $i$ at full load  \n",
    "- $k$: Number of active NICs  \n",
    "- $\\lambda_j$: Activity factor (0–1) of NIC $j$ (simplified as 1 if enabled, 0 if disabled)  \n",
    "- $P_{\\text{nic}, j}$: Power draw of NIC $j$ at full operation  \n",
    "\n",
    "**Note:**  \n",
    "- NIC power values are currently based on fixed, hardcoded estimates. These are placeholder values and do not reflect dynamic NIC behavior yet.  \n",
    "- CPU power is the dominant component in most server workloads, so this approximation still yields useful insights.  \n",
    "- By using a measured idle power ($P_{\\text{base}}$) for each node, we account for node-specific baseline consumption (e.g. mainboard, PSU, background services), which helps normalize comparisons across different server hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_linear, reg_poly, poly = fit_models(\n",
    "    model_df,\n",
    "    CONFIG[\"idle_power\"],\n",
    "    x_col=CONFIG[\"x_col\"],\n",
    "    fix_idle=CONFIG[\"fix_idle\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "\n",
    "Export the linear model (with or without fixed idle intercept) as a reusable .json file.  \n",
    "This can later be used for power estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting\n",
    "p_unit = reg_linear.coef_[0]\n",
    "intercept = CONFIG[\"idle_power\"] if CONFIG[\"fix_idle\"] else reg_linear.intercept_\n",
    "poly_coeffs = (reg_poly.coef_[2], reg_poly.coef_[1], reg_poly.intercept_)\n",
    "\n",
    "cpu_info = load_cpu_info(CONFIG) if CONFIG[\"model_kind\"] == \"cpu\" else load_cpu_info(CONFIG)  # optional to always include\n",
    "gpu_info = load_gpu_info(CONFIG) if CONFIG[\"model_kind\"] == \"gpu\" else load_gpu_info(CONFIG)  # optional to always include\n",
    "\n",
    "energy_model = save_energy_model(\n",
    "    config=CONFIG,\n",
    "    p_unit=p_unit,\n",
    "    intercept=intercept,\n",
    "    poly_coeffs=poly_coeffs,\n",
    "    mapping=run_mapping,\n",
    "    cpu_info=cpu_info,\n",
    "    gpu_info=gpu_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit Visualization\n",
    "\n",
    "We compare the measured power values to the predictions from:\n",
    "\n",
    "- **Linear Regression**  \n",
    "- **Polynomial Regression (Degree 2)**\n",
    "\n",
    "This plot helps assess how well each model captures the real trend in power usage as more CPU cores are utilized.\n",
    "\n",
    "We plot:\n",
    "\n",
    "- Measured values as scatter points  \n",
    "- Linear model as a red line  \n",
    "- Polynomial model as a blue curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_fit(model_df, reg_linear, reg_poly, poly, x_col=CONFIG[\"x_col\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Accuracy: Linear vs. Polynomial\n",
    "\n",
    "Below is a comparison table showing the actual power consumption values (real_power), the predicted values from both models, and their corresponding percentage errors.\n",
    "This helps evaluate how well each model fits the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model_errors(model_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_energy (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
